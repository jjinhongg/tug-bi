{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8606/3406541770.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Provide the access key from AWS SSM\n",
    "AWS_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "session = boto3.Session(aws_access_key_id=AWS_ACCESS_KEY, aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "ssm_client = session.client('ssm', region_name='ap-southeast-2')\n",
    "\n",
    "# Test the connection to AWS SSM\n",
    "response = ssm_client.get_parameters_by_path(\n",
    "    Path='/tug-dinlr/api/',\n",
    "    Recursive=True,\n",
    "    WithDecryption=True\n",
    ")\n",
    "\n",
    "# Function to get secrets from AWS SSM\n",
    "def get_secrets():\n",
    "    \n",
    "    response = ssm_client.get_parameters_by_path(\n",
    "        Path='/tug-dinlr/api/',\n",
    "        Recursive=True,\n",
    "        WithDecryption=True\n",
    "    )\n",
    "    \n",
    "    secrets = {param['Name'].split('/')[-1]: param['Value'] for param in response['Parameters']}\n",
    "    \n",
    "    return secrets\n",
    "\n",
    "# Get secrets\n",
    "params = get_secrets()\n",
    "\n",
    "# Set API details\n",
    "# Use the access token to interact with the Dinlr API\n",
    "base_url = \"https://api.dinlr.com/v1\"\n",
    "aheaders = {\n",
    "    \"Authorization\": f\"Bearer {params['ACCESS_TOKEN']}\"\n",
    "}\n",
    "\n",
    "rheaders = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "\n",
    "def get_locations(restaurant_id, headers):\n",
    "    \"\"\"Fetch locations from the API and return an iterable of (id, name).\"\"\"\n",
    "    response = requests.get(f\"https://api.dinlr.com/v1/{restaurant_id}/onlineorder/locations\", headers=headers)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract the 'id' and 'name' from each location and store them in a list of tuples\n",
    "    locations = [(location['id'], location['name']) for location in data['data']]\n",
    "    return locations\n",
    "\n",
    "locations = get_locations(params['RESTAURANT_ID'], aheaders)\n",
    "\n",
    "def convert_to_datetime(date_string):\n",
    "    return datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S+08:00\")\n",
    "\n",
    "def convert_to_datetime_timezone(date_string):\n",
    "    return datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "\n",
    "def is_token_expired(expiry_date_str):\n",
    "    \"\"\"Check if the access token has expired.\"\"\"\n",
    "    expiry_date = convert_to_datetime_timezone(expiry_date_str)\n",
    "    return datetime.now(utc_plus_8) >= expiry_date\n",
    "\n",
    "def refresh_access_token():\n",
    "    \"\"\"Request a new access token using the refresh token.\"\"\"\n",
    "    parameters = {\n",
    "        \"refresh_token\": params['REFRESH_TOKEN'],\n",
    "        \"client_id\": params['CLIENT_ID'],\n",
    "        \"client_secret\": params['CLIENT_SECRET'],\n",
    "        \"grant_type\": \"refresh_token\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(f\"{base_url}/{params['RESTAURANT_ID']}/oauth/token\", data=parameters, headers=rheaders)\n",
    "    response.raise_for_status()  # Ensure we raise an error for bad responses\n",
    "    data = response.json()\n",
    "\n",
    "    new_params = {\n",
    "        'ACCESS_TOKEN': data[\"access_token\"],\n",
    "        'REFRESH_TOKEN': data[\"refresh_token\"],\n",
    "        'EXPIRES_AT': (datetime.now(utc_plus_8) + timedelta(seconds=int(data[\"expires_in\"]))).strftime(\"%Y-%m-%dT%H:%M:%S+08:00\"),\n",
    "        'EXPIRES_IN': str(data[\"expires_in\"])\n",
    "    }\n",
    "\n",
    "    for key, value in new_params.items():\n",
    "        ssm_client.put_parameter(Name=f'/tug-dinlr/api/{key}', Value=value, Type='String', Overwrite=True)\n",
    "\n",
    "    return new_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the functions to get order and order details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all orders\n",
    "def get_all_orders(location_id, all=True, update_at_min=None, create_at_min=None, create_at_max=None):\n",
    "    orders = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        url = f\"{base_url}/{params['RESTAURANT_ID']}/onlineorder/orders?location_id={location_id}&page={page}\"\n",
    "        \n",
    "        if update_at_min:\n",
    "            update_at_min = update_at_min.replace(\"+\", \"%2B\")\n",
    "            url += f\"&update_at_min={update_at_min}\"\n",
    "        \n",
    "        if create_at_min:\n",
    "            create_at_min = convert_to_datetime(create_at_min).strftime(\"%Y-%m-%dT%H:%M:%S+08:00\").replace(\"+\", \"%2B\")\n",
    "            create_at_max = convert_to_datetime(create_at_max).strftime(\"%Y-%m-%dT%H:%M:%S+08:00\").replace(\"+\", \"%2B\") if create_at_max else None\n",
    "            url += f\"&create_at_min={create_at_min}\"\n",
    "            if create_at_max:\n",
    "                url += f\"&create_at_max={create_at_max}\"\n",
    "\n",
    "        response = requests.get(url, headers=aheaders)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()[\"data\"]\n",
    "\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        orders.extend(data)\n",
    "        page += 1\n",
    "\n",
    "    return orders\n",
    "\n",
    "# Function to get order details and add 'location' key\n",
    "def get_order_details(order_id, location='tug'):\n",
    "    url = f\"{base_url}/{params['RESTAURANT_ID']}/onlineorder/orders/{order_id}\"\n",
    "    response = requests.get(url, headers=aheaders)\n",
    "    response.raise_for_status()\n",
    "    order_details = response.json()[\"data\"]\n",
    "    order_details['location'] = location\n",
    "    return order_details\n",
    "\n",
    "# Function to upload to S3\n",
    "def upload_data_to_s3(data, bucket_name, prefix, date_format=\"%Y-%m-%d\"):\n",
    "    if not data:\n",
    "        logging.info(f\"No data to upload for {prefix}.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        last_created = convert_to_datetime(data[-1]['created_at']) + timedelta(seconds=1)\n",
    "        last_created_str = last_created.strftime(\"%Y-%m-%dT%H:%M:%S+08:00\")\n",
    "        file_key = f\"{prefix}_{datetime.now().strftime(date_format)}.json\"\n",
    "\n",
    "        s3.Object(bucket_name, file_key).put(Body=(bytes(json.dumps(data, indent=4).encode('UTF-8'))))\n",
    "        logging.info(f\"Successfully uploaded {prefix} data to S3.\")\n",
    "        return last_created_str\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to upload {prefix} data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read last item of json data into a pandas dataframe\n",
    "# master_TUG = pd.read_json('TUG_orders_migration.json')\n",
    "# master_EVENT = pd.read_json('EVENT_orders_migration.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get last 'created_at' date\n",
    "# last_created_TUG = master_TUG['created_at'].max() + pd.Timedelta(seconds=1)\n",
    "# last_created_EVENT = master_EVENT['created_at'].max() + pd.Timedelta(seconds=1)\n",
    "\n",
    "# # convert last_created to string in ISO 8601 format: \"2024-02-25T02:00:15+08:00\"\n",
    "# # last_created_TUG = last_created_TUG.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "# # last_created_EVENT = last_created_EVENT.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "# # print(f\"Last created TUG: {last_created_TUG}\")\n",
    "# # print(f\"Last created EVENT: {last_created_EVENT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get order for TUG at last updated date using the API\n",
    "# TUG_orders = get_all_orders(lTUG_ID, all=False, create_at_min=last_created_TUG)\n",
    "# EVENT_orders = get_all_orders(lEVENT_ID, all=False, create_at_min=last_created_EVENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# # Fetch all orders and their details\n",
    "# TUG_orders = get_all_orders(lTUG_ID)\n",
    "# EVENT_orders = get_all_orders(lEVENT_ID)\n",
    "\n",
    "# TUG_all_order_details = [get_order_details(order[\"id\"], location=\"tug\") for order in TUG_orders]\n",
    "# EVENT_all_order_details = [get_order_details(order[\"id\"], location=\"event\") for order in EVENT_orders]\n",
    "\n",
    "# # Get today's date\n",
    "# today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # Dump details to json with today's date as suffix in the filename\n",
    "# with open(f'TUG_orders_{today}.json', 'w') as f:\n",
    "#     json.dump(TUG_all_order_details, f)\n",
    "\n",
    "# with open(f'EVENT_orders_{today}.json', 'w') as f:\n",
    "#     json.dump(EVENT_all_order_details, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to DataFrame\n",
    "# TUG_df_orders = pd.DataFrame(TUG_all_order_details)\n",
    "# EVENT_df_orders = pd.DataFrame(EVENT_all_order_details)\n",
    "\n",
    "# parsed = json.loads(TUG_df_orders.to_json(orient=\"records\"))\n",
    "# with open(\"TUG_orders.json\", \"w\") as json_file:\n",
    "#     json.dump(parsed, json_file, indent=4)\n",
    "\n",
    "# parsed = json.loads(EVENT_df_orders.to_json(orient=\"records\"))\n",
    "# with open(\"EVENT_orders.json\", \"w\") as json_file:\n",
    "#     json.dump(parsed, json_file, indent=4)\n",
    "\n",
    "# # Curating data...\n",
    "# # Define a function to unnest and create separate tables\n",
    "# def unnest_json(df, field_name):\n",
    "#     return df.select(pl.col(field_name).arr.flatten().alias(field_name)).explode(field_name)\n",
    "\n",
    "# # Define a function to obtain json keys that has nested arrays\n",
    "# def get_nested_keys(json_data):\n",
    "#     nested_keys = []\n",
    "#     for key, value in json_data.items():\n",
    "#         if isinstance(value, list):\n",
    "#             nested_keys.append(key)\n",
    "#     return nested_keys\n",
    "\n",
    "# def check_nested_keys(json_data, parent_key=None):\n",
    "#     nested_keys = []\n",
    "#     for key, value in json_data.items():\n",
    "#         if isinstance(value, list):\n",
    "#             nested_keys.append((parent_key, key))\n",
    "#             for item in value:\n",
    "#                 nested_keys.extend(check_nested_keys(item, key))\n",
    "#         elif isinstance(value, dict):\n",
    "#             nested_keys.append((parent_key, key))\n",
    "#             nested_keys.extend(check_nested_keys(value, key))\n",
    "#     return nested_keys\n",
    "\n",
    "# nested_keys = check_nested_keys(json_data)\n",
    "\n",
    "# def get_order_schema(all_order_details):\n",
    "#     # Load the JSON data into Polars\n",
    "#     df = pl.DataFrame(all_order_details)\n",
    "\n",
    "#     # Get the nested keys\n",
    "#     nested_keys = get_nested_keys(all_order_details[0])\n",
    "\n",
    "#     # Create separate tables for each nested keys\n",
    "#     tables = {}\n",
    "#     for key in nested_keys:\n",
    "#         tables[key] = unnest_json(df, key)\n",
    "\n",
    "#     return tables\n",
    "\n",
    "\n",
    "\n",
    "# # Call the function with TUG_all_order_details\n",
    "# process_order_details(TUG_all_order_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUG_df_orders_items = pd.json_normalize(TUG_df_orders['items'].explode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to parquet / json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to Parquet with GZIP compression\n",
    "# parquet_file = '/mnt/data/orders.parquet.gzip'\n",
    "# df_orders.to_parquet(parquet_file, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
